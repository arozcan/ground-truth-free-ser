# Ground-Truth-Free Emotion Validation in Generative AI Speech

This repository contains the scripts and workflows used for validating emotions in synthetic speech 
generated by multiple TTS systems. The framework integrates **Emotion2Vec** and **WavLM** embeddings 
into a prototype-based classifier with the proposed **Emotion Adherence Score (EAS)**.

---

## üì¶ Requirements

- Python 3.9+
- PyTorch
- Transformers
- Fairseq (if using Fairseq models)
- Other dependencies listed in `requirements.txt`

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## üîÑ Workflow Overview

1. **Dataset Preparation**  
   Build CSV files containing emotion labels and TTS-generated audio paths.  

2. **Embedding Extraction**  
   Compute embeddings (Emotion2Vec + WavLM).  

3. **Prototype-based Classifier Training**  
   Train the prototype-based classifier with fused embeddings.  

4. **Evaluation**  
   Evaluate trained model (standard metrics, per-class reports, TTS system-specific analysis).  

5. **Baseline Evaluation**  
   Compare results with the standalone Emotion2Vec baseline.

---

## üöÄ Usage

### 1. Build SER CSV
Generate train/validation splits from the TTS audio dataset:

```bash
python build_ser_csv.py   --emotion_csv /home/arms/Workspace/emotion/vibes/emotion_sentences.csv   --tts_roots     /home/arms/Workspace/emotion/vibes/output/sentences/azure     /home/arms/Workspace/emotion/vibes/output/sentences/cosyvoice2     /home/arms/Workspace/emotion/vibes/output/sentences/genai     /home/arms/Workspace/emotion/vibes/output/sentences/openai   --train_out csv/train.csv   --val_out csv/val.csv   --val_ratio 0.2   --seed 42   --group_by text   --ensure_at_least_one_per_class
```

---

### 2. Prepare Embeddings
Extract **WavLM** and **Emotion2Vec** embeddings:

```bash
python prepare_embeddings.py
```

This will generate `.npy` embedding files and updated CSVs in `csv_with_emb_dual/`.

---

### 3. Train Prototype Classifier
Train the classifier with dual embeddings:

```bash
python proto_emotion_classifier.py   --mode train   --train_csv csv_with_emb_dual/train.csv   --val_csv   csv_with_emb_dual/val.csv   --emb_mode both   --fusion projcat   --proto_ema 0.5   --save_path proto_ckpt_dual.pt
```

---

### 4. Evaluation

#### Standard Evaluation
```bash
python proto_emotion_classifier.py   --mode eval   --val_csv csv_with_emb_dual/val.csv   --emb_mode both   --fusion projcat   --load_path proto_ckpt_dual.pt   --report_path eval_report.json
```

#### TTS System-Specific Evaluation
```bash
python proto_emotion_classifier.py   --mode eval_tts   --val_csv csv_with_emb_dual/val.csv   --emb_mode both   --fusion projcat   --load_path proto_ckpt_dual.pt   --report_path tts_eval_report.json
```

---

### 5. Baseline (Emotion2Vec only)

```bash
python eval_emotion2vec.py   --csv_path csv_with_emb_dual/val.csv
```

---

## üìä Outputs

- `eval_report.json` ‚Üí overall performance metrics (accuracy, F1, precision, recall, EAS).  
- `tts_eval_report.json` ‚Üí system-specific performance breakdown.  
- Confusion matrices and per-class reports (if enabled in scripts).  

---

## ‚úçÔ∏è Citation

If you use this code or methodology in your research, please cite our paper:

```bibtex
@misc{Ozcan2025SER,
  author       = {Ahmet Remzi Ozcan and Figen G. Alper},
  title        = {A Ground-Truth-Free Framework for Validating Emotions in Generative AI Speech Synthesis},
  year         = {2025},
  howpublished = {\url{https://github.com/arozcan/ground-truth-free-ser}},
  note         = {Accessed: 2025-10-04}
}

---

## üì¨ Contact

For questions, please contact:

- **Ahmet Remzi √ñzcan** ‚Äì ahmet.ozcan@btu.edu.tr
